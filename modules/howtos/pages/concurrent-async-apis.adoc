= Async & Reactive APIs
:description: The Couchbase {cpp} SDK allows the use, and mixing, of blocking and asynchronous APIs.
// :description: The Couchbase Scala SDK allows the use, and mixing, of three distinct APIs: blocking, asynchronous, and reactive.
:page-toclevels: 2
// :page-aliases: ROOT:async-programming,multiple-apis,ROOT:batching-operations



// Note to editors
// 
// This page pulls in content from -sdk-common-
// and code samples from -example-dir-
// 
// It can be seen built at wwww.

[abstract]
{description}


.Example of distributed mutex object, backed by a document inside a collection.
[source,cxx]
----
/* -*- Mode: C++; tab-width: 4; c-basic-offset: 4; indent-tabs-mode: nil -*- */

#include "core/logger/logger.hxx"
 
#include <couchbase/cluster.hxx>
 
#include <couchbase/best_effort_retry_strategy.hxx>
 
#include <asio.hpp>
#include <fmt/chrono.h>
#include <fmt/format.h>
 
#include <system_error>
#include <thread>
 
static constexpr auto connection_string{ "couchbase://127.0.0.1" };
static constexpr auto username{ "Administrator" };
static constexpr auto password{ "password" };
static constexpr auto bucket_name{ "default" };
static constexpr auto scope_name{ couchbase::scope::default_name };
static constexpr auto collection_name{ couchbase::collection::default_name };
 
class lock_aware_retry_strategy : public couchbase::best_effort_retry_strategy
{
  public:
    lock_aware_retry_strategy(couchbase::backoff_calculator calculator)
      : couchbase::best_effort_retry_strategy(calculator)
      , calculator_{ calculator }
    {
    }
 
    auto retry_after(const couchbase::retry_request& request, couchbase::retry_reason reason) -> couchbase::retry_action override
    {
        if (reason == couchbase::retry_reason::key_value_locked) {
            // here we use the same calculator as best_effort_retry_strategy, but it could be different one
            auto backoff_duration = calculator_(request.retry_attempts());
            fmt::print("retrying in {} because of \"key_value_locked\", attempt {}\n", backoff_duration, request.retry_attempts());
            return couchbase::retry_action{ backoff_duration };
        }
        return couchbase::best_effort_retry_strategy::retry_after(request, reason);
    }
 
  private:
    couchbase::backoff_calculator calculator_;
};
 
class couchbase_mutex
{
  public:
    static constexpr std::chrono::seconds default_lock_duration{ 15 };
    static constexpr std::chrono::seconds default_timeout{ 10 };
 
    couchbase_mutex(couchbase::collection collection,
                    std::string document_id,
                    std::chrono::seconds lock_duration = default_lock_duration,
                    std::chrono::seconds timeout = default_timeout)
      : collection_{ std::move(collection) }
      , document_id_{ std::move(document_id) }
      , lock_duration_{ lock_duration }
      , timeout_{ timeout }
    {
        auto options = couchbase::upsert_options{}.retry_strategy(retry_strategy_).timeout(timeout_);
        auto [ctx, resp] = collection_.upsert(document_id_, content_, options).get();
        if (ctx.ec()) {
            throw std::system_error(ctx.ec(),
                                    fmt::format(R"(unable to create mutex "{}" (retries: {}))", document_id_, ctx.retry_attempts()));
        }
        cas_ = resp.cas();
        fmt::print(
          "[created ] \"{}\", cas: {}, retries: {}, lock_duration: {}\n", document_id_, cas_.value(), ctx.retry_attempts(), lock_duration);
    }
 
    void lock()
    {
        std::scoped_lock lock(mutex_);
        auto options = couchbase::get_and_lock_options{}.retry_strategy(retry_strategy_).timeout(timeout_);
        auto [ctx, resp] = collection_.get_and_lock(document_id_, lock_duration_, options).get();
        if (ctx.ec()) {
            throw std::system_error(ctx.ec(),
                                    fmt::format(R"(unable to lock mutex "{}" (retries: {}))", document_id_, ctx.retry_attempts()));
        }
        cas_ = resp.cas();
        fmt::print("[locked  ] \"{}\", cas: {}, retries: {}\n", document_id_, cas_.value(), ctx.retry_attempts());
    }
 
    void unlock()
    {
        std::scoped_lock lock(mutex_);
        auto options = couchbase::unlock_options{}.timeout(timeout_);
        auto ctx = collection_.unlock(document_id_, cas_, options).get();
        if (ctx.ec()) {
            throw std::system_error(ctx.ec(),
                                    fmt::format(R"(unable to unlock mutex "{}" (retries: {}))", document_id_, ctx.retry_attempts()));
        }
        fmt::print("[unlocked] \"{}\", cas: {}, retries: {}\n", document_id_, cas_.value(), ctx.retry_attempts());
    }
 
  private:
    couchbase::collection collection_;
    std::string document_id_;
    std::chrono::seconds lock_duration_;
    std::chrono::seconds timeout_;
    couchbase::cas cas_;
    const std::string content_{ "__couchbase_mutex__" };
    mutable std::mutex mutex_{}; // regular mutex to protect internal state
    std::shared_ptr<lock_aware_retry_strategy> retry_strategy_{ std::make_shared<lock_aware_retry_strategy>(
      couchbase::controlled_backoff) }; // see also couchbase::exponential_backoff calculator
};
 
int
main()
{
    asio::io_context io;
    auto guard = asio::make_work_guard(io);
    std::thread io_thread([&io]() { io.run(); });
 
    auto options = couchbase::cluster_options(username, password);
    options.apply_profile("wan_development");
    auto [cluster, ec] = couchbase::cluster::connect(io, connection_string, options).get();
    auto collection = cluster.bucket(bucket_name).scope(scope_name).collection(collection_name);
 
    // Obtain thread_id for simplicity. Could be pid_id, if it was more portable.
    auto writer_id = fmt::format("thread:{}", std::hash<std::thread::id>()(std::this_thread::get_id()));
 
    // Create distributed mutex to protect modification of document "order:42".
    couchbase_mutex mutex(collection, "demo_mutex");
    {
        std::scoped_lock lock(mutex);
 
        // while lock is kept, other process cannot modify "order:42"
        const std::string document_id{ "order:42" };
        const tao::json::value basic_doc{ { "type", "book" },
                                          { "name", "Alice in Wonderland" },
                                          { "author", "Lewis Carroll" },
                                          { "price_usd", 4.0 },
                                          { "writer_id", writer_id } };
        auto [ctx, resp] = collection.upsert(document_id, basic_doc, {}).get();
        fmt::print("[stored  ] \"{}\", ec: {}, id: \"{}\", CAS: {}, writer_id: \"{}\"\n",
                   document_id,
                   ctx.ec() ? ctx.ec().message() : "success",
                   document_id,
                   resp.cas().value(),
                   writer_id);
 
        fmt::print(stderr, "[wait    ] pretend to do some work for 7 seconds (distributed mutex still locked)\n");
        std::this_thread::sleep_for(std::chrono::seconds{ 7 });
    }
 
    cluster.close();
    guard.reset();
 
    io_thread.join();
 
    return 0;
}
----






////
[abstract]
{description}

The Scala SDK provides three APIs, which can be freely mixed:

* A simple blocking one, that returns `Try`.
* An asynchronous one, that returns `Future`.
* A reactive one, that returns reactive primitives from the https://projectreactor.io/[Project Reactor] library, e.g. `Mono` and `Flux`.


== Using the Blocking API

This is the simplest API, in which all operations are synchronous and blocking.
A simple upsert example looks like this:

[source,scala]
----
include::devguide:example$scala/MultipleAPIs.scala[tag=upsert-simple,indent=0]
----

Methods in the blocking API that can error will return a Scala `Try` object,
which can either be a `Success` containing the result,
or a `Failure` containing a _Throwable_ exception that derives from `CouchbaseException`.

This can be pattern matched on, like this:

[source,scala]
----
include::devguide:example$scala/MultipleAPIs.scala[tag=upsert,indent=0]
----

Simple pattern matching like this works fine for simple examples, but starts to look complicated when doing multiple operations:

[source,scala]
----
include::devguide:example$scala/MultipleAPIs.scala[tag=get,indent=0]
----

Developers may prefer to use `flatMap`, which lets all the `Try` be checked in one place.
Here, the call to `collection.get` will only be attempted if the call to `collection.upsert` was successful -- that is, returned `Success`.

[source,scala]
----
include::devguide:example$scala/MultipleAPIs.scala[tag=get-map,indent=0]
----


== Using the Asynchronous API

The asynchronous API returns Scala `Future`, representing the execution of an asynchronous task and the promise of a future result.

Here's what a simple upsert looks like, handling `Success` or `Failure`
(note we are not actually blocking on the result here -- if you need that then you can use the methods in Scala's `Await`, or simply use the blocking Couchbase API):

[source,scala]
----
include::devguide:example$scala/MultipleAPIs.scala[tag=upsert-async,indent=0]
----

But, the compiler will fail to compile this, reporting that an implicit `ExecutionContext` cannot be found for onComplete.

As you may know, to do anything with a `Future` -- including `onComplete`, `map` and `flatMap` -- an `ExecutionContext` is required.
Here's how to create one that creates an unlimited thread-pool with named threads:

[source,scala]
----
include::devguide:example$scala/MultipleAPIs.scala[tag=async-import,indent=0]
----

Now there's an implicit ExecutionContext available, the upsert example will compile.

Let's see a more complex example combining operations together.
`Future` compose well, with `flatMap` being the most common tool:

[source,scala]
----
include::devguide:example$scala/MultipleAPIs.scala[tag=get-async,indent=0]
----

Interestingly, you'll see a couple of calls to `Try.get()` here.
These throw exceptions if the Try is `Failure`, and exceptions are usually something we try to avoid in Scala.
But here there's no problem as the `Future` will capture the exception,
and raise in so it can be handled in a `Failure`, as in the example.


== Using the Reactive API

Reactive Programming is an advanced paradigm designed to handle the challenges of building modern, network-aware and fault-tolerant programs.

The reactive API uses primitives from https://projectreactor.io/[Project Reactor], namely `Mono` (returning at most one result) and `Flux` (returning many).
These are compliant with the https://www.reactive-streams.org/[reactive streams specification], and so can easily be converted into other reactive implementations such as RxJava.

Here's how to do a simple reactive upsert operation, logging any errors:

[source,scala]
----
include::devguide:example$scala/MultipleAPIs.scala[tag=upsert-reactive,indent=0]
----

`upsert` returns `Mono[MutationResult]`.  The `subscribe` starts the operation - without a subscribe, nothing will happen.  The operation happens in the background.

Normally with reactive programming you will chain multiple operations together, and it's often possible to continue handling the chain in a reactive manner too.
For instance, many web frameworks allow an endpoint to stream back a reactive result.

In the rare cases where you need to block on a reactive primitive (say, in a unit test) you can do it like this:

[source,scala]
----
include::devguide:example$scala/MultipleAPIs.scala[tag=upsert-reactive-block,indent=0]
----

The `block` call here also does a `subscribe` under the hood.

Let's look at a more complex example, combining multiple operations.  As with `Future`, reactive primitives can be composed, with `flatMap` being the most common tool.

[source,scala]
----
include::devguide:example$scala/MultipleAPIs.scala[tag=get-reactive,indent=0]
----

Similar to the `Future` example, you'll note some calls to .get, on `Option` and `Try` that will throw exceptions if they do not contain `Some` or `Success` respectively.
This is fine -- the reactive code will capture it, and raise it in the standard reactive way -- e.g. through `doOnError` and similar operators.

While it's beyond the scope of this guide to teach reactive programming, it's important to touch on a handful of golden rules:

1. Never do blocking calls inside operators (operators are `doOnNext`, `flatMap`, etc.).  Those operators are executing on a limited number of threads, and blocking calls will limit concurrency.  Instead, convert the blocking call into a `Mono` or `Flux`, and `flatMap` to it.
2. Never subscribe to a reactive primitive inside an operator.  Instead, `flatMap` to it.
3. Always subscribe.  A `Mono` or `Flux` will not start until it's subscribed to.

=== Bulk Operations

For bulk operations, and applying the golden rules above,
call `flatMap` inside `SFlux`, as in the `upsert` example following:

[source,scala]
----
val json = JsonObject("foo" -> "bar", "baz" -> "qux")
val parallelism = 32

val result: Seq[Either[Throwable, MutationResult]] = SFlux.fromIterable(Seq("doc1", "doc2", "doc3"))
      .flatMap(docId => collection.reactive.upsert(docId, json)
              .map(result => Right(result))
              .onErrorResume(err => SMono.just(Left(err))),
          parallelism)
      .collectSeq()
      .block()
----


== Choosing an API

So which API should you choose?

It's really down to you and the needs of your application.
If you're already writing code in a synchronous way already then it may make sense to continue that way.
If you're writing a web application that supports reactive streams, it may make sense to use the reactive API.
And you can use different APIs at different times.

The most important thing to consider is when streaming back large queries from Query, Full Text Search, and Analytics.
Here, the reactive API will provide full backpressure:
that is, if your application is processing rows slower than the service is returning them, then automatically fewer rows will be requested from the service to give the application time to catch up.
The upshot of this is that few rows are ever buffered in-memory, and the application shouldn't get out-of-memory exceptions.

By contrast, the blocking and asynchronous APIs will buffer all rows in-memory before returning them to the application.  This will generally be fine, but if you're doing any large queries then you may want to consider the reactive API.
////
